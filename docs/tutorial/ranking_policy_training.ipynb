{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3d66a85d15b9ca",
   "metadata": {},
   "source": [
    "# Ranking policy training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72baa24ee119f0",
   "metadata": {},
   "source": [
    "The tree nodes in MCTS are expanded by an expansion function approximated by a policy graph neural network. The policy network is composed of two parts: molecular representation and reaction rule prediction parts. In the representation part, the molecular graph is converted to a single vector by graph convolutional layers. The training set structure and the prediction part architecture depend on the type of policy network, particularly the ranking or filtering policy network. The training dataset for ranking policy network consists of pairs of reactions and corresponding reaction rules extracted from it. The products of the reaction are transformed to the CGR encoded as a molecular graph with the one-hot encoded label vector where the positive label corresponds to the reaction rule. The prediction part is terminated with the softmax function generating the “probability of successful application” of each reaction rule to a given input molecular graph, which can be used for the reaction rules “ranking”.\n",
    "All the reaction rules predicted by the ranking or policy neural network are sorted by predicted reaction rule probability and the first N (usually N = 50) of reaction rules are selected to be applied to the current precursor in the expansion step.\n",
    "\n",
    "**Training set.** The training dataset for ranking policy network consists of pairs of reactions and corresponding reaction rules extracted from it. The products of the reaction are transformed to the CGR encoded as a molecular graph with the one-hot encoded label vector where the positive label corresponds to the reaction rule. The prediction part is terminated with the softmax function generating the “probability of successful application” of each reaction rule to a given input molecular graph, which can be used for the reaction rules “ranking”.\n",
    "\n",
    "Frst, we define the training configuration using the `PolicyNetworkConfig` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ecf78-7103-4fa1-8ab0-88c995d40350",
   "metadata": {},
   "source": [
    "## 1. Set up input and output data locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944dc45c-c5b3-4255-82de-667edf364b3e",
   "metadata": {},
   "source": [
    "The input data will be downloaded from the [HuggingFace repository](https://huggingface.co/Laboratoire-De-Chemoinformatique/SynPlanner) to the current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928513a8-df22-4927-937a-230799d49d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fa28d84be042af8a48ac322ed7e25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 25 files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from synplan.utils.loading import download_all_data\n",
    "\n",
    "# download SynPlanner data\n",
    "data_folder = Path(\"synplan_data\").resolve()\n",
    "download_all_data(save_to=data_folder)\n",
    "\n",
    "# results folder\n",
    "results_folder = Path(\"tutorial_results\").resolve()\n",
    "results_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# input data\n",
    "# use default filtered data from tutorial folder or replace with custom data prepared with data curation tutorial\n",
    "# be sure that you use the same reaction dataset from which the reaction rules were extracted \n",
    "filtered_data_path = results_folder.joinpath(\"uspto_filtered.smi\")\n",
    "reaction_rules_path = results_folder.joinpath(\"uspto_reaction_rules.pickle\")\n",
    "\n",
    "# output_data\n",
    "ranking_policy_network_folder = results_folder.joinpath(\"ranking_policy_network\")\n",
    "ranking_policy_dataset_path = ranking_policy_network_folder.joinpath(\"ranking_policy_dataset.pt\") # the generated training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9e6ee052a8553",
   "metadata": {},
   "source": [
    "### 1. Configuration\n",
    "**Configuration parameters**:\n",
    "\n",
    "| Parameter        | Default | Description                                                     |\n",
    "|------------------|---------|-----------------------------------------------------------------|\n",
    "| vector_dim       | 512     | The dimension of the hidden layers                              |\n",
    "| num_conv_layers  | 5       | The number of convolutional layers                              |\n",
    "| learning_rate    | 0.0005  | The learning rate                                               |\n",
    "| dropout          | 0.4     | The dropout value                                               |\n",
    "| num_epoch        | 100     | The number of training epochs                                   |\n",
    "| batch_size       | 1000    | The size of the training batch of input molecular graphs        |\n",
    "\n",
    "The ranking or filtering policy network architecture and training hyperparameters can be adjusted in the training configuration yaml file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0ad0a2-4fad-47f5-ab5c-6f5b38343e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synplan.utils.config import PolicyNetworkConfig\n",
    "from synplan.ml.training.supervised import create_policy_dataset, run_policy_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9457427e36dd79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = PolicyNetworkConfig(\n",
    "    policy_type=\"ranking\",  # the type of policy network\n",
    "    num_conv_layers=5,  # the number of graph convolutional layers in the network\n",
    "    vector_dim=512,  # the dimensionality of the final embedding vector\n",
    "    learning_rate=0.0008,  # the learning rate for the training process\n",
    "    dropout=0.4,  # the dropout rate\n",
    "    num_epoch=100,  # the number of epochs for training\n",
    "    batch_size=100,\n",
    ")  # the size of training batch of input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5db29397d4d95",
   "metadata": {},
   "source": [
    "### 2. Creating the training set\n",
    "\n",
    "Next, we create the policy dataset using the `create_policy_dataset` function. This involves specifying paths to the reaction rules and the reaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2905b131ed0268c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of reactions processed: 69445 [09:36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 52507, validation set size: 13127\n"
     ]
    }
   ],
   "source": [
    "datamodule = create_policy_dataset(\n",
    "    dataset_type=\"ranking\",\n",
    "    reaction_rules_path=reaction_rules_path,\n",
    "    molecules_or_reactions_path=filtered_data_path,\n",
    "    output_path=ranking_policy_dataset_path,\n",
    "    batch_size=training_config.batch_size,\n",
    "    num_cpus=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e9e8cd9423f30",
   "metadata": {},
   "source": [
    "### 3. Run the policy network training\n",
    "\n",
    "Finally, we train the policy network using the `run_policy_training` function. This step involves feeding the dataset and the training configuration into the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59c420b56fb3e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy network balanced accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "run_policy_training(\n",
    "    datamodule,  # the prepared data module for training\n",
    "    config=training_config,  # the training configuration\n",
    "    results_path=ranking_policy_network_folder,\n",
    ")  # path to save the training results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synplan",
   "language": "python",
   "name": "synplan_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
